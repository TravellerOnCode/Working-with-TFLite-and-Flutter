{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grading_TFLite.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-yRwQgYf6fQK",
        "jA9kXlue7YoV",
        "IyvGUYN28oM4"
      ],
      "authorship_tag": "ABX9TyOyteKuhJPV3x4ql7w3FwMu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TravellerOnCode/Working-with-TFLite-and-Flutter/blob/master/Grading_TFLite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2jlT4_M5nx6"
      },
      "source": [
        "#Loading Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7QcZEP9z7iM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "edadaac4-8777-44d7-cd48-ae6a3d12d8e4"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9MUQvrB8z01"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slLcJwloAjec"
      },
      "source": [
        "#Required Libraries\n",
        "import matplotlib.pyplot as plt \n",
        "import fnmatch \n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import io\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "import unicodedata\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLNMgIk3AtQ_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b238d62c-c39d-4044-dcff-838b022a757a"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop_words = stopwords.words('english')\n",
        "print(stop_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRfY33Ss5r6p"
      },
      "source": [
        "#Loading and Cleaning Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJZ9_CJQ5voK"
      },
      "source": [
        "#Load the data and store in a data frame\n",
        "def load_data():\n",
        "    \n",
        "    df = pd.read_csv(r'essays_and_scores.csv',encoding='latin-1')\n",
        "    #data = df[['essay_id','essay_set','essay','rater1_domain1','rater1_domain1','domain1_score']].copy()\n",
        "    data = df[['essay_set','essay','rater1_domain1','rater1_domain1','domain1_score']].copy()\n",
        "    data = data.dropna() #drop all NaN values\n",
        "    #print(data)\n",
        "    #check details of the data\n",
        "    print(data['essay'].apply(len).describe())\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atMpRogs5vqz"
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "\n",
        "collection = contraction_mapping.keys()\n",
        "\n",
        "def expand_words(s):\n",
        "    if s in collection:\n",
        "        return contraction_mapping[s]\n",
        "    else:\n",
        "        return s\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdXbNWIe5vvL"
      },
      "source": [
        "#garbage = {'@ORGANIZATION?':'organization','@NAME?':'number','@NUM':'number','@CAPS?':'name','@DR':'name','Dr?':'doctor','Mr?':'mister','Mrs?':'mistress','@LOCATION?':'location','@CITY?':'location','@PERSON?':'name','@MONEY?':'money','@DATE?':'date','@MONTH?':'month'}\n",
        "garbage = {'ORGANIZATION?':'organization','NAME?':'name','NUM':'number','CAPS?':'name','DR':'name','Dr?':'doctor','Mr?':'mister','Mrs?':'mistress',\n",
        "           'LOCATION?':'location','CITY?':'location','PERSON?':'name','MONEY?':'money','DATE?':'date','MONTH?':'month'}\n",
        "\n",
        "def replace_garbage_words(s):\n",
        "    for i in garbage:\n",
        "        match = fnmatch.fnmatch(s, i)\n",
        "        if match == True:\n",
        "              return (garbage[i])\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhTCqQ3A5vyP"
      },
      "source": [
        "def clean_data(data):\n",
        "    essay_data = []\n",
        "    essay_lengths = []\n",
        "    essay_scores = []\n",
        "    essay_category = []\n",
        "    max_score = [12,6,3,3,4,4,24,60]\n",
        "    for index, row in data.iterrows():\n",
        "    #for text in data['essay']:\n",
        "        text = row['essay']\n",
        "        length = len(text.split(' '))\n",
        "        #if length<50:\n",
        "         #     continue\n",
        "        #if length>2000:\n",
        "         #     continue\n",
        "        #Normalise (normalize) unicode data in Python to remove umlauts, accents etc.\n",
        "        unicode_data = text\n",
        "        text = unicodedata.normalize('NFKD', unicode_data).encode('ASCII', 'ignore')\n",
        "        text = str(text)\n",
        "        #print (normal)\n",
        "\n",
        "        # split into words\n",
        "        tokens = word_tokenize(text)\n",
        "        #replace garbage words\n",
        "        tokens = [replace_garbage_words(w) for w in tokens]  \n",
        "        tokens = [expand_words(w) for w in tokens]\n",
        "    \n",
        "        #for n,w in enumerate(tokens):\n",
        "        #  tokens[n]=replace_garbage_words(w)\n",
        "        # remove punctuation from each word\n",
        "        table = str.maketrans('', '', string.punctuation)\n",
        "        stripped = [w.translate(table) for w in tokens]\n",
        "        # remove remaining tokens that are not alphabetic\n",
        "        words = [word for word in stripped if word.isalpha()]\n",
        "\n",
        "        # convert to lower case\n",
        "        words = [w.lower() for w in words]\n",
        "    \n",
        "\n",
        "        str1 = \"\"\n",
        "        for i in words:\n",
        "            str1 = str1 + i + \" \"\n",
        "        str2 = str1[1:]\n",
        "        str2.lstrip()\n",
        "        essay_data.append(str2)\n",
        "        essay_lengths.append(length)\n",
        "    \n",
        "        category = row['essay_set']\n",
        "        score = row['domain1_score']\n",
        "        score = round((score/max_score[category-1])*10) #taking percentile scores\n",
        "        essay_scores.append(score)\n",
        "        essay_category.append(category)\n",
        "\n",
        "    new_data = pd.DataFrame(list(zip(essay_data,essay_scores)),columns = ['Essay','Score'])\n",
        "    print(new_data['Essay'].apply(len).describe())\n",
        "    return (new_data,essay_lengths,essay_scores,essay_category)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFgDlNsT5vtv"
      },
      "source": [
        "def generate_test_train(new_data):\n",
        "    #shuffle the dataset before splitting\n",
        "    new_data1 = shuffle(new_data)\n",
        "    #new_data1 = shuffle(new_data1)\n",
        "    #new_data1 = shuffle(new_data1)\n",
        "\n",
        "    train = new_data1.sample(frac=0.8)\n",
        "    new_data1.drop(train.index, axis=0, inplace=True)\n",
        "    valid = new_data1.sample(frac=0.5)\n",
        "    new_data1.drop(valid.index, axis=0, inplace=True)\n",
        "    test = new_data1\n",
        "    print(train.shape , test.shape , valid.shape )\n",
        "\n",
        "    def return_data(df):\n",
        "        return list(df['Essay']), np.array(df['Score'])\n",
        "\n",
        "    # Apply it to the three splits\n",
        "    train_essay, train_score = return_data(train)\n",
        "    valid_essay, valid_score = return_data(valid)\n",
        "    test_essay, test_score = return_data(test)\n",
        "    #print(train_essay[0], train_score[0])\n",
        "    #return a tuple of values \n",
        "    return (train_essay,train_score,valid_essay,valid_score,test_essay,test_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le7hvWC-6SkJ"
      },
      "source": [
        "#Calling Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2jhiWll6Vds",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "637f2e74-390d-4449-cf35-cf58abf7ce01"
      },
      "source": [
        "data = load_data()\n",
        "print('*******************')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    12977.000000\n",
            "mean      1215.871234\n",
            "std        958.321377\n",
            "min          8.000000\n",
            "25%        527.000000\n",
            "50%        900.000000\n",
            "75%       1670.000000\n",
            "max       6098.000000\n",
            "Name: essay, dtype: float64\n",
            "*******************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-Cm7N_m6Vgq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "24394045-349b-49ea-ab0f-3106b1d9eb95"
      },
      "source": [
        "new_data,essay_lengths,essay_scores,essay_category = clean_data(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    12977.000000\n",
            "mean      1171.974262\n",
            "std        915.155314\n",
            "min          9.000000\n",
            "25%        513.000000\n",
            "50%        869.000000\n",
            "75%       1613.000000\n",
            "max       5963.000000\n",
            "Name: Essay, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hbC44m96VoN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "f8dec8b8-ee39-46f1-e5ae-60f2840dd78c"
      },
      "source": [
        "new_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Essay</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dear local newspaper i think effects computer...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dear name name i believe that using computers...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dear name name name more and more people use ...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dear local newspaper name i have found that ma...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dear location i know having computers has a p...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12972</th>\n",
              "      <td>in most stories mothers and daughters are eit...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12973</th>\n",
              "      <td>i never understood the meaning laughter is th...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12974</th>\n",
              "      <td>when you laugh is name out of habit or is name...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12975</th>\n",
              "      <td>trippin on fences i am years young and in tho...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12976</th>\n",
              "      <td>many people believe that laughter can improve...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12977 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Essay  Score\n",
              "0       dear local newspaper i think effects computer...      7\n",
              "1       dear name name i believe that using computers...      8\n",
              "2       dear name name name more and more people use ...      6\n",
              "3      dear local newspaper name i have found that ma...      8\n",
              "4       dear location i know having computers has a p...      7\n",
              "...                                                  ...    ...\n",
              "12972   in most stories mothers and daughters are eit...      6\n",
              "12973   i never understood the meaning laughter is th...      5\n",
              "12974  when you laugh is name out of habit or is name...      7\n",
              "12975   trippin on fences i am years young and in tho...      7\n",
              "12976   many people believe that laughter can improve...      7\n",
              "\n",
              "[12977 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZQ4MlvU6Vr9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "3449e059-8c9a-41e2-8856-5eb865718f73"
      },
      "source": [
        "train_essay,train_score,valid_essay,valid_score,test_essay,test_score = generate_test_train(new_data)\n",
        "print(train_essay[10])\n",
        "print(train_score[10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10382, 2) (1297, 2) (1298, 2)\n",
            "in the excerpt the name mast by name the architects of the empire state building faced obstacles in attempting to allow dirigibles to dock thereone of the problems the builders encountered was that the dirigible didnt have a suitable landing area the architechs concluded that they couldnt just drop a name mast on top of their building because it would add stress to its frame so they had to strengthen and modify it to make it workanother obstacle was the fact that most dirigibles ran on hydrogen which is highly flamable the builders realized how dangerous that could be especially above a densely populated area such as downtown new york they also realized that nature itself was their biggest obstace winds were constatly shifting due to violent air currents and they knew that this idea was neither practical nor safe lastly there was a law against airships flying too low over urban areas which would make their idea illegal and unsuccessful \n",
            "8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yRwQgYf6fQK"
      },
      "source": [
        "#Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8X0xd6X6hwC"
      },
      "source": [
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbtes54h6wTM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d8b5329-4172-4f63-b026-77a55be23bac"
      },
      "source": [
        "# using keras tokenizer here\n",
        "token = tf.keras.preprocessing.text.Tokenizer(oov_token = \"<OOV>\")\n",
        "    \n",
        "#token = text.Tokenizer(num_words=None,oov_token=oov_tok)\n",
        "#max_len = 1100\n",
        "max_len = 1024\n",
        "token.fit_on_texts(list(train_essay) + list(valid_essay))\n",
        "word_index = token.word_index\n",
        "len(word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40027"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5oAz06NPEZn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "282e2ac9-da74-4acc-c286-8a3343c82bf0"
      },
      "source": [
        "type(token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras_preprocessing.text.Tokenizer"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WACnFa0rPIn7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f87b383d-89fd-44da-c73d-b6059e002e2f"
      },
      "source": [
        "type(word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaCO8s4WJaS-"
      },
      "source": [
        "import json\n",
        "with open('tokenizer.txt','w') as file:\n",
        "    file.write(json.dumps(word_index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSn9ZbRoRSUu"
      },
      "source": [
        "with open('tokenizer.txt','r') as f, open('tokenizer_labels.txt', 'w') as file:\n",
        "    for line in f:\n",
        "       for word in line.split(','):\n",
        "           file.write(word + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUfSjatL6wWL"
      },
      "source": [
        "xtrain_seq = token.texts_to_sequences(train_essay)\n",
        "xvalid_seq = token.texts_to_sequences(valid_essay)\n",
        "xtest_seq = token.texts_to_sequences(test_essay)\n",
        "\n",
        "#zero pad the sequences\n",
        "preproc_train = tf.keras.preprocessing.sequence.pad_sequences(xtrain_seq, maxlen=max_len,padding=padding_type, truncating=trunc_type)\n",
        "preproc_valid = tf.keras.preprocessing.sequence.pad_sequences(xvalid_seq, maxlen=max_len,padding=padding_type, truncating=trunc_type)\n",
        "preproc_test = tf.keras.preprocessing.sequence.pad_sequences(xtest_seq, maxlen=max_len,padding=padding_type, truncating=trunc_type)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clqkFxKlod0y"
      },
      "source": [
        "preproc_train = tf.cast(preproc_train,tf.float32)\n",
        "preproc_valid = tf.cast(preproc_valid,tf.float32)\n",
        "preproc_test = tf.cast(preproc_test,tf.float32)\n",
        "\n",
        "train_score = tf.cast(train_score,tf.float32)\n",
        "test_score = tf.cast(test_score,tf.float32)\n",
        "valid_score = tf.cast(valid_score,tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9OgP_9M6waU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52bb4a6d-781a-48f0-89ef-74a9c4a80bd7"
      },
      "source": [
        "type(preproc_test[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.framework.ops.EagerTensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQdXK1jv6wfp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc4544f6-98aa-417a-bf55-5d0375671c98"
      },
      "source": [
        "len(test_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1297"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA9kXlue7YoV"
      },
      "source": [
        "#GloVe Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWNmlxEs6weH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e20c6832-e314-4638-89e1-1adb1d2b6fe5"
      },
      "source": [
        "!gsutil cp gs://cloud-training-demos/courses/machine_learning/deepdive/09_sequence/text_classification/glove.6B.200d.txt glove.6B.200d.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/09_sequence/text_classification/glove.6B.200d.txt...\n",
            "| [1 files][661.3 MiB/661.3 MiB]                                                \n",
            "Operation completed over 1 objects/661.3 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Muvsn1TJ7fOB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "20545a5d-c987-4080-b9ba-769df8fe68c2"
      },
      "source": [
        "embeddings_index = {}\n",
        "f = open('glove.6B.200d.txt','r',encoding='utf-8')\n",
        "for line in tqdm(f):\n",
        "    values = line.split(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray([float(val) for val in values[1:]])\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000it [00:24, 16566.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NshhP-Sb7fSq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb4641e0-2fc3-46c6-da5a-e34a2810530a"
      },
      "source": [
        "# create an embedding matrix for the words we have in the dataset\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, 200))\n",
        "for word, i in tqdm(word_index.items()):\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40027/40027 [00:00<00:00, 593656.29it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X79wyulF7fMf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD1iL58C7fKw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfFov5b36I0F"
      },
      "source": [
        "#Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrU1-l38z8ZB"
      },
      "source": [
        "def build_model():\n",
        "    # A simple bidirectional LSTM with glove embeddings and one dense layer\n",
        "    model = tf.keras.Sequential()\n",
        "    \n",
        "    model.add(tf.keras.layers.Embedding(len(word_index) + 1,\n",
        "                     200,\n",
        "                     weights=[embedding_matrix],\n",
        "                     input_length=max_len,\n",
        "                     trainable=False))\n",
        "    \n",
        "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(1, activation='relu'))\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.MeanSquaredError(), \n",
        "        optimizer = tf.keras.optimizers.RMSprop(\n",
        "                            learning_rate=0.001),\n",
        "        metrics=['mae'])\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V07NOF13z8cq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "4f4ee8b9-3a03-4a3a-cc8f-79398899fa72"
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 1024, 200)         8005600   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 1024, 512)         935936    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024, 512)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 128)               295424    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 9,237,089\n",
            "Trainable params: 1,231,489\n",
            "Non-trainable params: 8,005,600\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osCGTSL5CR7J"
      },
      "source": [
        "#Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vKy0WwQCbAn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "082dddab-c90d-4fd1-9a75-1614e54a5a62"
      },
      "source": [
        "H = model.fit(preproc_train,\n",
        "         train_score,\n",
        "         validation_data=(preproc_valid, valid_score),\n",
        "         batch_size=64,\n",
        "         epochs=20,\n",
        "         verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "163/163 [==============================] - 54s 332ms/step - loss: 6.8003 - mae: 2.0926 - val_loss: 5.6934 - val_mae: 1.8462\n",
            "Epoch 2/20\n",
            "163/163 [==============================] - 54s 331ms/step - loss: 5.3346 - mae: 1.8384 - val_loss: 3.4871 - val_mae: 1.4858\n",
            "Epoch 3/20\n",
            "163/163 [==============================] - 54s 329ms/step - loss: 3.4114 - mae: 1.4444 - val_loss: 2.7634 - val_mae: 1.2887\n",
            "Epoch 4/20\n",
            "163/163 [==============================] - 53s 328ms/step - loss: 3.1057 - mae: 1.3797 - val_loss: 2.7035 - val_mae: 1.2966\n",
            "Epoch 5/20\n",
            "163/163 [==============================] - 54s 329ms/step - loss: 2.9471 - mae: 1.3416 - val_loss: 2.4537 - val_mae: 1.2183\n",
            "Epoch 6/20\n",
            "163/163 [==============================] - 54s 329ms/step - loss: 2.9434 - mae: 1.3372 - val_loss: 2.4788 - val_mae: 1.2182\n",
            "Epoch 7/20\n",
            "163/163 [==============================] - 54s 328ms/step - loss: 2.7633 - mae: 1.2943 - val_loss: 2.6706 - val_mae: 1.2357\n",
            "Epoch 8/20\n",
            "163/163 [==============================] - 54s 328ms/step - loss: 2.5996 - mae: 1.2541 - val_loss: 2.2759 - val_mae: 1.1866\n",
            "Epoch 9/20\n",
            "163/163 [==============================] - 54s 328ms/step - loss: 2.5080 - mae: 1.2255 - val_loss: 2.0929 - val_mae: 1.1258\n",
            "Epoch 10/20\n",
            "163/163 [==============================] - 53s 328ms/step - loss: 2.3729 - mae: 1.1861 - val_loss: 2.0194 - val_mae: 1.1068\n",
            "Epoch 11/20\n",
            "163/163 [==============================] - 53s 328ms/step - loss: 2.3387 - mae: 1.1823 - val_loss: 2.1613 - val_mae: 1.1220\n",
            "Epoch 12/20\n",
            "163/163 [==============================] - 53s 328ms/step - loss: 2.2367 - mae: 1.1551 - val_loss: 1.9723 - val_mae: 1.0619\n",
            "Epoch 13/20\n",
            "163/163 [==============================] - 54s 329ms/step - loss: 2.1787 - mae: 1.1317 - val_loss: 2.5842 - val_mae: 1.2125\n",
            "Epoch 14/20\n",
            "163/163 [==============================] - 53s 328ms/step - loss: 2.0869 - mae: 1.1170 - val_loss: 2.0547 - val_mae: 1.0817\n",
            "Epoch 15/20\n",
            "163/163 [==============================] - 53s 327ms/step - loss: 2.0452 - mae: 1.0954 - val_loss: 2.4104 - val_mae: 1.1633\n",
            "Epoch 16/20\n",
            "163/163 [==============================] - 53s 327ms/step - loss: 1.9158 - mae: 1.0558 - val_loss: 2.1426 - val_mae: 1.1008\n",
            "Epoch 17/20\n",
            "163/163 [==============================] - 53s 328ms/step - loss: 1.8504 - mae: 1.0363 - val_loss: 2.2056 - val_mae: 1.0869\n",
            "Epoch 18/20\n",
            "163/163 [==============================] - 53s 328ms/step - loss: 1.7487 - mae: 1.0070 - val_loss: 2.1592 - val_mae: 1.0721\n",
            "Epoch 19/20\n",
            "163/163 [==============================] - 53s 327ms/step - loss: 1.6780 - mae: 0.9857 - val_loss: 2.3099 - val_mae: 1.0826\n",
            "Epoch 20/20\n",
            "163/163 [==============================] - 53s 327ms/step - loss: 1.5997 - mae: 0.9615 - val_loss: 2.2809 - val_mae: 1.1041\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20-210icCUb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "a7853705-4e25-4ab9-8918-f808d901109a"
      },
      "source": [
        "H = model.fit(preproc_train,\n",
        "         train_score,\n",
        "         validation_data=(preproc_valid, valid_score),\n",
        "         batch_size=64,\n",
        "         epochs=20,\n",
        "         verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "163/163 [==============================] - 77s 470ms/step - loss: 6.6682 - mae: 2.0545 - val_loss: 4.7421 - val_mae: 1.7662\n",
            "Epoch 2/20\n",
            "163/163 [==============================] - 76s 464ms/step - loss: 4.1149 - mae: 1.5832 - val_loss: 3.3812 - val_mae: 1.5020\n",
            "Epoch 3/20\n",
            "163/163 [==============================] - 76s 463ms/step - loss: 3.9500 - mae: 1.5491 - val_loss: 2.9670 - val_mae: 1.3230\n",
            "Epoch 4/20\n",
            "163/163 [==============================] - 76s 464ms/step - loss: 3.1260 - mae: 1.3823 - val_loss: 2.9272 - val_mae: 1.3815\n",
            "Epoch 5/20\n",
            "163/163 [==============================] - 76s 464ms/step - loss: 2.9979 - mae: 1.3499 - val_loss: 2.5317 - val_mae: 1.2550\n",
            "Epoch 6/20\n",
            "163/163 [==============================] - 75s 463ms/step - loss: 2.7428 - mae: 1.2896 - val_loss: 2.5406 - val_mae: 1.2193\n",
            "Epoch 7/20\n",
            "163/163 [==============================] - 76s 463ms/step - loss: 2.6439 - mae: 1.2645 - val_loss: 3.8080 - val_mae: 1.5483\n",
            "Epoch 8/20\n",
            "163/163 [==============================] - 75s 462ms/step - loss: 2.5425 - mae: 1.2397 - val_loss: 2.5718 - val_mae: 1.1773\n",
            "Epoch 9/20\n",
            "163/163 [==============================] - 76s 464ms/step - loss: 2.4347 - mae: 1.2042 - val_loss: 2.5643 - val_mae: 1.1789\n",
            "Epoch 10/20\n",
            "163/163 [==============================] - 75s 463ms/step - loss: 2.2981 - mae: 1.1710 - val_loss: 2.3376 - val_mae: 1.1705\n",
            "Epoch 11/20\n",
            "163/163 [==============================] - 76s 464ms/step - loss: 2.2050 - mae: 1.1499 - val_loss: 2.2691 - val_mae: 1.1335\n",
            "Epoch 12/20\n",
            "163/163 [==============================] - 75s 463ms/step - loss: 2.1367 - mae: 1.1308 - val_loss: 2.4230 - val_mae: 1.1976\n",
            "Epoch 13/20\n",
            "163/163 [==============================] - 76s 464ms/step - loss: 2.0641 - mae: 1.1003 - val_loss: 2.3002 - val_mae: 1.1404\n",
            "Epoch 14/20\n",
            "163/163 [==============================] - 75s 463ms/step - loss: 1.9774 - mae: 1.0770 - val_loss: 2.6197 - val_mae: 1.2628\n",
            "Epoch 15/20\n",
            "163/163 [==============================] - 76s 463ms/step - loss: 1.8955 - mae: 1.0573 - val_loss: 2.3026 - val_mae: 1.1096\n",
            "Epoch 16/20\n",
            "163/163 [==============================] - 75s 462ms/step - loss: 1.8763 - mae: 1.0511 - val_loss: 2.3789 - val_mae: 1.1823\n",
            "Epoch 17/20\n",
            "163/163 [==============================] - 76s 464ms/step - loss: 1.7443 - mae: 1.0093 - val_loss: 2.4720 - val_mae: 1.2014\n",
            "Epoch 18/20\n",
            "163/163 [==============================] - 75s 463ms/step - loss: 1.6743 - mae: 0.9936 - val_loss: 2.5180 - val_mae: 1.1600\n",
            "Epoch 19/20\n",
            "163/163 [==============================] - 75s 463ms/step - loss: 1.5923 - mae: 0.9635 - val_loss: 2.1831 - val_mae: 1.0516\n",
            "Epoch 20/20\n",
            "163/163 [==============================] - 75s 462ms/step - loss: 1.5144 - mae: 0.9364 - val_loss: 2.3710 - val_mae: 1.1127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE1sk_RF8JnE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clLtCTEx8J1t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pMDuK1pzjS4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "history_dict = H\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgcGm9LXzjgg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAlDy_uN8KP2"
      },
      "source": [
        "#Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_Kcn4FT8QZi"
      },
      "source": [
        "y_pred = model.predict(preproc_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ1rxLlz8Qkv"
      },
      "source": [
        "def Kappa_Score(test_score,y_pred):\n",
        "    # Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
        "    result = cohen_kappa_score(test_score,np.around(y_pred),weights='quadratic')\n",
        "    print(\"Kappa Score: {}\".format(result))\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDmBPEo98aBA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fd76a89-6cb6-4508-8f62-db07337165b0"
      },
      "source": [
        "r = Kappa_Score(test_score,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kappa Score: 0.7640648375830119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0mpK34ez39R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da507c68-cbe2-4930-ff2a-c8e5228867fc"
      },
      "source": [
        "#new\n",
        "r = Kappa_Score(test_score,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kappa Score: 0.7505809274317109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYH-EZV-IG-6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWh3JO0LyHOg"
      },
      "source": [
        "Reduced Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flo55oNfyNKM"
      },
      "source": [
        "preproc_test_reduced = preproc_test[:50]\n",
        "test_score_reduced = test_score[:50]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zeqo8bqyNa7"
      },
      "source": [
        "y_pred_reduced = model.predict(preproc_test_reduced)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1X6VWKHz03m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d82883bd-4549-43d6-b323-598b335a8121"
      },
      "source": [
        "r = Kappa_Score(test_score_reduced,y_pred_reduced)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kappa Score: 0.7021667865995043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svGW29ZS7n-j"
      },
      "source": [
        "#Saving and Converting the Model to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU7yy2sYz8fP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "3b68a2bd-8ecb-4b30-e8d0-06463100eed0"
      },
      "source": [
        "export_dir = 'saved_model/1'\n",
        "tf.saved_model.save(model,export_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: saved_model/1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdnbHkIhxqWn"
      },
      "source": [
        "\n",
        "# Show model size in KBs.\n",
        "#original_model = \n",
        "float_model_size = len(model) / 1024\n",
        "print('Float model size = %dKBs.' % float_model_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdrzLkmfDFtl"
      },
      "source": [
        "Convert to TFLite (without optimization) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7B_xCiHz8jO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0XmkJsTz8a3"
      },
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3Yy5QvdDk8m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af8a1ace-4a91-4d69-e403-581b2b85d97e"
      },
      "source": [
        "tflite_model = converter.convert()\n",
        "print('Converted !')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qafy9MQkD1QR"
      },
      "source": [
        "tflite_model_file = 'model_grading_.tflite'\n",
        "\n",
        "with open(tflite_model_file, \"wb\") as f:\n",
        "      f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymvvIa1vD2KE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3aa5b94-4291-4bb6-c785-5a58bbecad21"
      },
      "source": [
        "# Show model size in KBs.\n",
        "float_model_size = len(tflite_model) / 1024\n",
        "print('Float model size = %dKBs.' % float_model_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Float model size = 37154KBs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyr4UzumDoPD"
      },
      "source": [
        "Convert to TFLite (with optimization) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2defeWMJIr0N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHE9Wcjy47gf"
      },
      "source": [
        "#New Approach\n",
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "#converter.optimizations = [optimization]\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "#converter.optimizations = [tf.lite.Optimize.DEFAULT]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KXPdQvt_BIW"
      },
      "source": [
        "#mnist_train, _ = tf.keras.datasets.mnist.load_data()\n",
        "texts = tf.cast(preproc_train[0], tf.float32)\n",
        "data_ds = tf.data.Dataset.from_tensor_slices((texts)).batch(1)\n",
        "def representative_data_gen():\n",
        "  for input_value in data_ds.take(100):\n",
        "    yield [input_value]\n",
        "\n",
        "converter.representative_dataset = representative_data_gen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn1R7Ub78Bjw"
      },
      "source": [
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb1LP-ck19mF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "db9bdd7a-09c0-480a-f481-5e2e33d33b93"
      },
      "source": [
        "tflite_model = converter.convert()\n",
        "print('Converted !')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;31mRuntimeError\u001b[0m: Only models with a single subgraph are supported, model had 9 subgraphs",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/optimize/calibrator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_content)\u001b[0m\n\u001b[1;32m     50\u001b[0m       self._calibrator = (_calibration_wrapper.CalibrationWrapper\n\u001b[0;32m---> 51\u001b[0;31m                           .CreateWrapperCPPFromBuffer(model_content))\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: <built-in function CalibrationWrapper_CreateWrapperCPPFromBuffer> returned a result with an error set",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-a4f1b7c7d92e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Converted !'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_calibration_quantize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m       result = self._calibrate_quantize_model(\n\u001b[0;32m--> 522\u001b[0;31m           result, constants.FLOAT, constants.FLOAT)\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_calibrate_quantize_model\u001b[0;34m(self, result, inference_input_type, inference_output_type)\u001b[0m\n\u001b[1;32m    259\u001b[0m                                 inference_output_type):\n\u001b[1;32m    260\u001b[0m     \u001b[0mallow_float\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_int8_target_required\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     \u001b[0mcalibrate_quantize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_calibrator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalibrator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_calibrate_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcalibrate_quantize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentative_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/optimize/calibrator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_content)\u001b[0m\n\u001b[1;32m     51\u001b[0m                           .CreateWrapperCPPFromBuffer(model_content))\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to parse the model: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calibrator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to parse the model.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to parse the model: <built-in function CalibrationWrapper_CreateWrapperCPPFromBuffer> returned a result with an error set."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YStFz4L3Icd"
      },
      "source": [
        "tflite_model_file = 'model_grading_2.tflite'\n",
        "\n",
        "with open(tflite_model_file, \"wb\") as f:\n",
        "      f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1oHs92892Ga",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74ae5f66-ee0e-4e54-9722-b9aab01802ed"
      },
      "source": [
        "\n",
        "# Show model size in KBs.\n",
        "float_model_size = len(tflite_model) / 1024\n",
        "print('Float model size = %dKBs.' % float_model_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Float model size = 37149KBs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa31qKs_4MvI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9587ab6c-bc15-44c8-e8da-a87671917442"
      },
      "source": [
        "\n",
        "# Show model size in KBs.\n",
        "float_model_size = len(tflite_model) / 1024\n",
        "print('Float model size = %dKBs.' % float_model_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Float model size = 37090KBs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-xm6ixS5X4O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n_35quf4-qQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyvGUYN28oM4"
      },
      "source": [
        "#Testing with an Interpreter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhT4rX4Y8tnc"
      },
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "#output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI-V2g8M8tlK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "61786caf-31f5-4c61-8bb2-1d61e5f8e5b0"
      },
      "source": [
        "# Gather results for the randomly sampled test images\n",
        "predictions2 = []\n",
        "test_scores2 = []\n",
        "test_datas2 = []\n",
        "\n",
        "for i in range(50):\n",
        "  text = preproc_test[i]\n",
        "  score = test_score[i]\n",
        "  #text = np.expand_dims(text, axis=0).astype(np.float32)\n",
        "  text = tf.expand_dims(text,0)\n",
        "  interpreter.set_tensor(input_index, text)\n",
        "  interpreter.invoke()\n",
        "  #print(output[0])\n",
        "  predictions2.append(interpreter.get_tensor(output_index))\n",
        "  #predictions.append(output[0])\n",
        "  test_scores2.append(score)\n",
        "  test_datas2.append(text)\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDUJs0OteAy3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "72be17ce-f1f5-417d-c5c7-7553b30ee50b"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.16938  ],\n",
              "       [9.272753 ],\n",
              "       [4.4491844],\n",
              "       ...,\n",
              "       [8.657941 ],\n",
              "       [9.52352  ],\n",
              "       [5.1031284]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNf8KHsJeDrT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "45bc0f0b-b0aa-4724-e45b-6dc796588273"
      },
      "source": [
        "p = []\n",
        "for i in predictions2:\n",
        "  l = []\n",
        "  l.append(i[0][0])\n",
        "  p.append(l)\n",
        "p = np.array(p)\n",
        "print(p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8.169376 ]\n",
            " [9.272752 ]\n",
            " [4.4491835]\n",
            " [7.1341734]\n",
            " [6.3053713]\n",
            " [4.063136 ]\n",
            " [9.403208 ]\n",
            " [9.558133 ]\n",
            " [7.890703 ]\n",
            " [6.9883833]\n",
            " [8.98264  ]\n",
            " [4.2297544]\n",
            " [6.8236227]\n",
            " [5.155761 ]\n",
            " [3.2727332]\n",
            " [7.1645994]\n",
            " [6.5297613]\n",
            " [5.9954357]\n",
            " [5.1021347]\n",
            " [6.1679497]\n",
            " [4.2695417]\n",
            " [8.333868 ]\n",
            " [9.586123 ]\n",
            " [3.203994 ]\n",
            " [4.856967 ]\n",
            " [6.689765 ]\n",
            " [9.369832 ]\n",
            " [6.3990326]\n",
            " [6.6721754]\n",
            " [8.477364 ]\n",
            " [6.432741 ]\n",
            " [7.180423 ]\n",
            " [7.1647053]\n",
            " [3.90539  ]\n",
            " [6.918458 ]\n",
            " [9.423333 ]\n",
            " [5.5150948]\n",
            " [8.722359 ]\n",
            " [8.405177 ]\n",
            " [5.991638 ]\n",
            " [9.04976  ]\n",
            " [7.4759064]\n",
            " [2.5397172]\n",
            " [7.0149364]\n",
            " [3.0809972]\n",
            " [6.4736013]\n",
            " [8.369404 ]\n",
            " [2.869701 ]\n",
            " [6.2348747]\n",
            " [5.373827 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJDFFrxhin0P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8662bb36-6806-49c6-f97b-af8e46da97d5"
      },
      "source": [
        "print(test_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Tensor: shape=(), dtype=float32, numpy=9.0>, <tf.Tensor: shape=(), dtype=float32, numpy=8.0>, <tf.Tensor: shape=(), dtype=float32, numpy=7.0>, <tf.Tensor: shape=(), dtype=float32, numpy=3.0>, <tf.Tensor: shape=(), dtype=float32, numpy=5.0>, <tf.Tensor: shape=(), dtype=float32, numpy=3.0>, <tf.Tensor: shape=(), dtype=float32, numpy=7.0>, <tf.Tensor: shape=(), dtype=float32, numpy=3.0>, <tf.Tensor: shape=(), dtype=float32, numpy=7.0>, <tf.Tensor: shape=(), dtype=float32, numpy=8.0>, <tf.Tensor: shape=(), dtype=float32, numpy=10.0>, <tf.Tensor: shape=(), dtype=float32, numpy=8.0>, <tf.Tensor: shape=(), dtype=float32, numpy=7.0>, <tf.Tensor: shape=(), dtype=float32, numpy=6.0>, <tf.Tensor: shape=(), dtype=float32, numpy=7.0>, <tf.Tensor: shape=(), dtype=float32, numpy=5.0>, <tf.Tensor: shape=(), dtype=float32, numpy=7.0>, <tf.Tensor: shape=(), dtype=float32, numpy=7.0>, <tf.Tensor: shape=(), dtype=float32, numpy=7.0>, <tf.Tensor: shape=(), dtype=float32, numpy=5.0>, <tf.Tensor: shape=(), dtype=float32, numpy=8.0>, <tf.Tensor: shape=(), dtype=float32, numpy=5.0>, <tf.Tensor: shape=(), dtype=float32, numpy=10.0>, <tf.Tensor: shape=(), dtype=float32, numpy=8.0>, <tf.Tensor: shape=(), dtype=float32, numpy=10.0>, <tf.Tensor: shape=(), dtype=float32, numpy=3.0>, <tf.Tensor: shape=(), dtype=float32, numpy=8.0>, <tf.Tensor: shape=(), dtype=float32, numpy=5.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=7.0>, <tf.Tensor: shape=(), dtype=float32, numpy=5.0>, <tf.Tensor: shape=(), dtype=float32, numpy=6.0>, <tf.Tensor: shape=(), dtype=float32, numpy=7.0>, <tf.Tensor: shape=(), dtype=float32, numpy=7.0>, <tf.Tensor: shape=(), dtype=float32, numpy=5.0>, <tf.Tensor: shape=(), dtype=float32, numpy=5.0>, <tf.Tensor: shape=(), dtype=float32, numpy=6.0>, <tf.Tensor: shape=(), dtype=float32, numpy=3.0>, <tf.Tensor: shape=(), dtype=float32, numpy=7.0>, <tf.Tensor: shape=(), dtype=float32, numpy=7.0>, <tf.Tensor: shape=(), dtype=float32, numpy=8.0>, <tf.Tensor: shape=(), dtype=float32, numpy=5.0>, <tf.Tensor: shape=(), dtype=float32, numpy=7.0>, <tf.Tensor: shape=(), dtype=float32, numpy=2.0>, <tf.Tensor: shape=(), dtype=float32, numpy=8.0>, <tf.Tensor: shape=(), dtype=float32, numpy=6.0>, <tf.Tensor: shape=(), dtype=float32, numpy=7.0>, <tf.Tensor: shape=(), dtype=float32, numpy=5.0>, <tf.Tensor: shape=(), dtype=float32, numpy=7.0>, <tf.Tensor: shape=(), dtype=float32, numpy=8.0>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REMnNUx28tjN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b8d571db-ddb1-44b0-9410-85c0b2f454d9"
      },
      "source": [
        "print(len(test_scores2))\n",
        "print(len(predictions))\n",
        "print(len(test_score))\n",
        "#r2 = Kappa_Score(test_scores2,p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n",
            "50\n",
            "1297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnY3Z6nm9Jsx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "269b72f2-0a59-4f3a-e7b6-4e203cbd534e"
      },
      "source": [
        "r2 = Kappa_Score(test_score[:50],p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kappa Score: 0.8758240765826786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUAvbgLs8tgS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "28452728-cfb0-4c4b-da68-e5b56396cd2c"
      },
      "source": [
        "print(\"Comparison between two Models !\")\n",
        "print(\"Original Model Score: \",r)\n",
        "print(\"TFLite Model: Optimization = Storage \",r2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comparison between two Models !\n",
            "Original Model Score:  0.7640648375830119\n",
            "TFLite Model: Optimization = Storage  0.8758240765826786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egg-WZ3DBrfQ"
      },
      "source": [
        "print(\"TFLite Model: Optimization = Speed \",r3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOtrX9ER5DPe"
      },
      "source": [
        "#Quantization of the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnESbGGi4-wh"
      },
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "#converter.optimizations = [optimization]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAWNTSc24-uk"
      },
      "source": [
        "# Re-convert the model to TF Lite using quantization.\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quantized_model = converter.convert()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ8nczaF4-no"
      },
      "source": [
        "# Show model size in KBs.\n",
        "quantized_model_size = len(tflite_quantized_model) / 1024\n",
        "print('Quantized model size = %dKBs,' % quantized_model_size)\n",
        "print('which is about %d%% of the float model size.'\\\n",
        "      % (quantized_model_size * 100 / float_model_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e8BY3Xs5eL_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAu4HpAlFT_E"
      },
      "source": [
        "#Using a different Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TOMLDT1HK1z"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycBD_9bLGk8y"
      },
      "source": [
        "num_tokens = len(word_index) + 1\n",
        "embedding_dim = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWi38_H-GPxB"
      },
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "    input_length=max_len,\n",
        "    trainable=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sokivqzvGcYV"
      },
      "source": [
        "model.add(tf.keras.layers.Embedding(len(word_index) + 1,\n",
        "                     200,\n",
        "                     weights=[embedding_matrix],\n",
        "                     input_length=max_len,\n",
        "                     trainable=False))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfAsOsesFWby",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "3b8d6149-67cd-4ec2-a415-9e6a7c05190c"
      },
      "source": [
        "model2 = tf.keras.Sequential()\n",
        "\n",
        "model2.add(embedding_layer)\n",
        "model2.add(tf.keras.layers.Conv1D(128, 5, activation=\"relu\"))\n",
        "model2.add(tf.keras.layers.MaxPooling1D(5))\n",
        "model2.add(tf.keras.layers.Conv1D(128, 5, activation=\"relu\"))   \n",
        "model2.add(tf.keras.layers.MaxPooling1D(5))\n",
        "model2.add(tf.keras.layers.Conv1D(128, 5, activation=\"relu\"))\n",
        "model2.add(tf.keras.layers.GlobalMaxPooling1D())\n",
        "model2.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
        "model2.add(tf.keras.layers.Dropout(0.5))\n",
        "model2.add(tf.keras.layers.Dense(1, activation=\"relu\")) \n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 1024, 200)         8005600   \n",
            "_________________________________________________________________\n",
            "conv1d_12 (Conv1D)           (None, 1020, 128)         128128    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1 (None, 204, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_13 (Conv1D)           (None, 200, 128)          82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1 (None, 40, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_14 (Conv1D)           (None, 36, 128)           82048     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_4 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 8,314,465\n",
            "Trainable params: 308,865\n",
            "Non-trainable params: 8,005,600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9RQZEfmFzNP"
      },
      "source": [
        "model2.compile(\n",
        "        loss=tf.keras.losses.MeanSquaredError(), \n",
        "        optimizer = tf.keras.optimizers.RMSprop(\n",
        "                            learning_rate=0.001),\n",
        "        metrics=['mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U50YODXjFzYj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "106b4695-0e0a-4854-84d4-b6a4e93d367f"
      },
      "source": [
        "H = model2.fit(preproc_train,\n",
        "         train_score,\n",
        "         validation_data=(preproc_valid, valid_score),\n",
        "         batch_size=64,\n",
        "         epochs=20,\n",
        "         verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "163/163 [==============================] - 5s 29ms/step - loss: 7.3085 - mae: 2.0107 - val_loss: 3.9575 - val_mae: 1.5464\n",
            "Epoch 2/20\n",
            "163/163 [==============================] - 5s 28ms/step - loss: 4.6514 - mae: 1.7179 - val_loss: 2.4990 - val_mae: 1.2107\n",
            "Epoch 3/20\n",
            "163/163 [==============================] - 5s 28ms/step - loss: 3.9906 - mae: 1.5816 - val_loss: 2.5574 - val_mae: 1.2491\n",
            "Epoch 4/20\n",
            "163/163 [==============================] - 5s 28ms/step - loss: 3.6889 - mae: 1.5152 - val_loss: 2.4632 - val_mae: 1.2298\n",
            "Epoch 5/20\n",
            "163/163 [==============================] - 5s 28ms/step - loss: 3.3275 - mae: 1.4428 - val_loss: 2.4102 - val_mae: 1.2101\n",
            "Epoch 6/20\n",
            "163/163 [==============================] - 5s 28ms/step - loss: 3.0290 - mae: 1.3703 - val_loss: 2.3481 - val_mae: 1.1829\n",
            "Epoch 7/20\n",
            "163/163 [==============================] - 5s 28ms/step - loss: 2.7547 - mae: 1.3114 - val_loss: 2.8208 - val_mae: 1.3433\n",
            "Epoch 8/20\n",
            "163/163 [==============================] - 5s 28ms/step - loss: 2.4760 - mae: 1.2425 - val_loss: 2.4659 - val_mae: 1.2189\n",
            "Epoch 9/20\n",
            "163/163 [==============================] - 5s 28ms/step - loss: 2.2998 - mae: 1.1946 - val_loss: 2.4373 - val_mae: 1.2214\n",
            "Epoch 10/20\n",
            "163/163 [==============================] - 5s 28ms/step - loss: 2.1124 - mae: 1.1535 - val_loss: 5.2067 - val_mae: 1.8871\n",
            "Epoch 11/20\n",
            "163/163 [==============================] - 5s 28ms/step - loss: 2.0036 - mae: 1.1145 - val_loss: 4.0656 - val_mae: 1.6380\n",
            "Epoch 12/20\n",
            "163/163 [==============================] - 4s 28ms/step - loss: 1.8952 - mae: 1.0789 - val_loss: 3.0318 - val_mae: 1.3735\n",
            "Epoch 13/20\n",
            "163/163 [==============================] - 4s 27ms/step - loss: 1.8047 - mae: 1.0476 - val_loss: 2.7792 - val_mae: 1.2725\n",
            "Epoch 14/20\n",
            "163/163 [==============================] - 4s 27ms/step - loss: 1.7169 - mae: 1.0161 - val_loss: 2.8082 - val_mae: 1.2835\n",
            "Epoch 15/20\n",
            "163/163 [==============================] - 4s 27ms/step - loss: 1.6955 - mae: 1.0015 - val_loss: 2.7340 - val_mae: 1.2636\n",
            "Epoch 16/20\n",
            "163/163 [==============================] - 4s 28ms/step - loss: 1.5882 - mae: 0.9741 - val_loss: 2.5344 - val_mae: 1.2287\n",
            "Epoch 17/20\n",
            "163/163 [==============================] - 5s 28ms/step - loss: 1.5760 - mae: 0.9650 - val_loss: 2.5511 - val_mae: 1.2240\n",
            "Epoch 18/20\n",
            "163/163 [==============================] - 5s 28ms/step - loss: 1.5090 - mae: 0.9451 - val_loss: 4.8002 - val_mae: 1.8111\n",
            "Epoch 19/20\n",
            "163/163 [==============================] - 5s 28ms/step - loss: 1.4950 - mae: 0.9415 - val_loss: 2.5064 - val_mae: 1.2065\n",
            "Epoch 20/20\n",
            "163/163 [==============================] - 5s 28ms/step - loss: 1.4270 - mae: 0.9166 - val_loss: 2.5657 - val_mae: 1.2435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCQ-mkOHHoQi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4PSgKOpH0HG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Zxf4VvSH3X9"
      },
      "source": [
        "Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqYNbOdeH7In"
      },
      "source": [
        "y_pred2 = model2.predict(preproc_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Uspb1uZH7AR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81a93654-67d8-4c0c-d0cb-519a3b341c6c"
      },
      "source": [
        "r = Kappa_Score(test_score,y_pred2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kappa Score: 0.7176941936328558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UL0j--YH65Z"
      },
      "source": [
        "preproc_test_reduced2 = preproc_test[:50]\n",
        "test_score_reduced2 = test_score[:50]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb0Rl8reH6y2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2296d35f-4188-438d-db6b-51a682510354"
      },
      "source": [
        "y_pred_reduced2 = model2.predict(preproc_test_reduced2)\n",
        "r = Kappa_Score(test_score_reduced2,y_pred_reduced2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kappa Score: 0.670495198644323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiXJ6NDtH0Od",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f0728d06-67cd-4458-cad4-c487f3b5bd6e"
      },
      "source": [
        "export_dir = 'saved_model/2'\n",
        "tf.saved_model.save(model,export_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/2/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HYKtQvyH0K6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbJ1f-vtI20K"
      },
      "source": [
        "TFLite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z0mZUp3I6FC"
      },
      "source": [
        "texts = tf.cast(preproc_train[0], tf.float32)\n",
        "data_ds = tf.data.Dataset.from_tensor_slices((texts)).batch(2)\n",
        "def representative_data_gen():\n",
        "  for input_value in data_ds.take(100):\n",
        "    yield [input_value]\n",
        "\n",
        "converter.representative_dataset = representative_data_gen\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAhfAUUAI31S"
      },
      "source": [
        "#New Approach\n",
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model2)\n",
        "#converter.optimizations = [optimization]\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "#mnist_train, _ = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X6BsN9CI6IY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55304f63-b01b-46c8-c9ed-b027da5b9867"
      },
      "source": [
        "\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "#converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "print('Converted !')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69x8pFqeJFEg"
      },
      "source": [
        "tflite_model_file = 'model_grading_quant2.tflite'\n",
        "\n",
        "with open(tflite_model_file, \"wb\") as f:\n",
        "      f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nJ_i9FtQ--q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8056e659-5e1c-481a-d18c-097b128d9c7c"
      },
      "source": [
        "# Show model size in KBs.\n",
        "float_model_size = len(tflite_model) / 1024\n",
        "print('Float model size = %dKBs.' % float_model_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Float model size = 8127KBs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQDeGB0xQ_Bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9310410-3e66-43a6-84ac-ce88bf15875f"
      },
      "source": [
        "# Show model size in KBs.\n",
        "float_model_size = len(tflite_model) / 1024\n",
        "print('Float model size = %dKBs.' % float_model_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Float model size = 8127KBs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpmY_8m8RQ9T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81b02974-a45a-40f0-d700-4c735956b94d"
      },
      "source": [
        "# Show model size in KBs.\n",
        "float_model_size = len(tflite_model) / 1024\n",
        "print('Float model size (float16) = %dKBs.' % float_model_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Float model size (float16) = 16246KBs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-myuD4PPSiWU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owuTTEE4TjJJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOioIAkLTjgA"
      },
      "source": [
        "#Testing new interpreter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw-v9pdQTlz7"
      },
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "#output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szhIdWKaTofq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "0d1ba44e-46ec-452c-e8d0-8b8679302f60"
      },
      "source": [
        "# Gather results for the randomly sampled test images\n",
        "predictions2 = []\n",
        "test_scores2 = []\n",
        "test_datas2 = []\n",
        "\n",
        "for i in range(50):\n",
        "  text = preproc_test[i]\n",
        "  score = test_score[i]\n",
        "  #text = np.expand_dims(text, axis=0).astype(np.float32)\n",
        "  text = tf.expand_dims(text,0)\n",
        "  interpreter.set_tensor(input_index, text)\n",
        "  interpreter.invoke()\n",
        "  #print(output[0])\n",
        "  predictions2.append(interpreter.get_tensor(output_index))\n",
        "  #predictions.append(output[0])\n",
        "  test_scores2.append(score)\n",
        "  test_datas2.append(text)\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOteAv6WTokX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbF9u0EgTtvf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "8612582f-c373-4e4a-f5e6-9904e6e6abe5"
      },
      "source": [
        "p = []\n",
        "for i in predictions2:\n",
        "  l = []\n",
        "  l.append(i[0][0])\n",
        "  p.append(l)\n",
        "p = np.array(p)\n",
        "print(p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4.6155157]\n",
            " [3.954429 ]\n",
            " [7.147621 ]\n",
            " [4.7092924]\n",
            " [5.7188396]\n",
            " [7.6974525]\n",
            " [4.0079374]\n",
            " [6.6991386]\n",
            " [7.392479 ]\n",
            " [5.359309 ]\n",
            " [1.6638725]\n",
            " [9.032124 ]\n",
            " [6.8230877]\n",
            " [6.624441 ]\n",
            " [4.371544 ]\n",
            " [9.78329  ]\n",
            " [6.5079107]\n",
            " [7.2174625]\n",
            " [6.522917 ]\n",
            " [8.107827 ]\n",
            " [5.6272507]\n",
            " [4.213863 ]\n",
            " [6.212867 ]\n",
            " [5.7143955]\n",
            " [6.1007137]\n",
            " [6.5669994]\n",
            " [5.8562155]\n",
            " [4.5475397]\n",
            " [9.486784 ]\n",
            " [6.542404 ]\n",
            " [4.5877132]\n",
            " [6.058076 ]\n",
            " [7.505533 ]\n",
            " [6.6254854]\n",
            " [6.1992455]\n",
            " [6.3393593]\n",
            " [6.481964 ]\n",
            " [7.1225805]\n",
            " [8.634988 ]\n",
            " [8.7665615]\n",
            " [7.043956 ]\n",
            " [4.7625523]\n",
            " [7.662154 ]\n",
            " [5.204397 ]\n",
            " [2.9797738]\n",
            " [7.8173246]\n",
            " [6.9222193]\n",
            " [7.417098 ]\n",
            " [7.5704737]\n",
            " [4.240813 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a93xqz1KT0HU"
      },
      "source": [
        "print(len(test_scores2))\n",
        "#print(len(predictions))\n",
        "print(len(test_score))\n",
        "#r2 = Kappa_Score(test_scores2,p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVpHeocFT0PM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b62ca1c-8817-415f-b6eb-bc57a1137a27"
      },
      "source": [
        "r2 = Kappa_Score(test_score[:50],p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kappa Score: 0.6666036129764494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBy0K6_kUNLJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}